{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alice_in_the_Wonderland.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOuouT7c5W0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "87f6db5d-15ea-4e0b-dd7c-4b5582e28e98"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/AdarshKumar712/Alice-in-Wonderland.git cloned-repo/\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 8\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n",
            "/content/cloned-repo\n",
            "README.md  SimpleRNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZVq3UF49hRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ede7502c-071d-433d-a951-35b573509878"
      },
      "source": [
        "cd SimpleRNN"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cloned-repo/SimpleRNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg6IP1Vm9nWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the required modules\n",
        "from __future__ import print_function\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import vis_utils\n",
        "import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQQAR-XU9xgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Dataset and preprocess\n",
        "alice = open('alice.txt', 'rb')\n",
        "lines = []\n",
        "for line in alice:\n",
        "    line = line.strip().lower()\n",
        "    line = line.decode('ascii', 'ignore')\n",
        "    if len(line)==0:\n",
        "        continue\n",
        "    lines.append(line)\n",
        "alice.close()\n",
        "text = \" \".join(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGBBjDEy911B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating sets for comparison in RNN\n",
        "## Identifying the characters and creating lookup dictionaries for them\n",
        "chars = set([c for c in text])\n",
        "len_chars = len(chars)\n",
        "chars2index = dict([(c, i) for i, c in enumerate(chars)])\n",
        "index2chars = dict([(i, c) for i, c in enumerate(chars)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiI0X5y_-Aj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQ_LEN = 20\n",
        "STEP = 1\n",
        "input_chars = []\n",
        "label_chars = []\n",
        "for i in range(0, len(text)-SEQ_LEN, STEP):\n",
        "    input_chars.append(text[i:i+SEQ_LEN])\n",
        "    label_chars.append(text[i+SEQ_LEN])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teCl8tYq-QcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorizing Labels\n",
        "x = np.zeros((len(input_chars), SEQ_LEN, len_chars), dtype=np.bool)\n",
        "y = np.zeros((len(input_chars), len_chars), dtype=np.bool)\n",
        "\n",
        "for i, input_char in enumerate(input_chars):\n",
        "    for j, ch in enumerate(input_char):\n",
        "        x[i, j, chars2index[ch]] = 1\n",
        "    y[i, chars2index[label_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoGUHftV-RL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HyperParameter Definition\n",
        "\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "NUM_PREDS_PER_EPOCH = 100\n",
        "\n",
        "# Creating the Model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(128,return_sequences = True,input_shape=(SEQ_LEN, len_chars), unroll=True)))\n",
        "model.add(Bidirectional(LSTM(128,return_sequences = True, unroll=True)))\n",
        "model.add(LSTM(128,activation = 'relu',unroll = True,return_sequences = False))\n",
        "model.add(Dense(len_chars, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfGAA2Jk-YjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70b5a4b3-18ce-47bf-d5f2-f83c1ddfa367"
      },
      "source": [
        "# Predicting and testing the model\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "    print('='*50)\n",
        "    print(\"Iteration #: %d\"%(iteration))\n",
        "    model.fit(x, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "    print(\"Generating text from the seed : %s \\n\"%(test_chars))\n",
        "    print(test_chars, end='')\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "        X_test = np.zeros((1, SEQ_LEN, len_chars))\n",
        "        for i, ch in enumerate(test_chars):\n",
        "            X_test[0, i, chars2index[ch]] = 1\n",
        "        pred = model.predict(X_test, verbose=False)[0]\n",
        "        y_pred = index2chars[np.argmax(pred)]\n",
        "        print(y_pred, end='')\n",
        "        test_chars=test_chars[1:] + y_pred\n",
        "print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 172s 1ms/step - loss: 2.3942 - acc: 0.3162\n",
            "Generating text from the seed : were seated on their \n",
            "\n",
            "were seated on their the the the the the the the the the the the the the the the the the the the the the the the the the==================================================\n",
            "Iteration #: 1\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 914us/step - loss: 1.8692 - acc: 0.4450\n",
            "Generating text from the seed : id the king eagerly, \n",
            "\n",
            "id the king eagerly, and the mound the mound the mound the mound the mound the mound the mound the mound the mound the m==================================================\n",
            "Iteration #: 2\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 912us/step - loss: 1.6520 - acc: 0.5049\n",
            "Generating text from the seed :  was, or longitude e \n",
            "\n",
            " was, or longitude even the mouse to the mouse to the mouse to the mouse to the mouse to the mouse to the mouse to the m==================================================\n",
            "Iteration #: 3\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 913us/step - loss: 1.5124 - acc: 0.5418\n",
            "Generating text from the seed : to get through the d \n",
            "\n",
            "to get through the dormouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse th==================================================\n",
            "Iteration #: 4\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 914us/step - loss: 1.4111 - acc: 0.5696\n",
            "Generating text from the seed : ed out of the house  \n",
            "\n",
            "ed out of the house and the way all the way all the way all the way all the way all the way all the way all the way all ==================================================\n",
            "Iteration #: 5\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 147s 925us/step - loss: 1.3359 - acc: 0.5889\n",
            "Generating text from the seed :  in wonderland *** * \n",
            "\n",
            " in wonderland *** ****  the mock turtle the project gutenberg-tm electronic works and the project gutenberg-tm electron==================================================\n",
            "Iteration #: 6\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 921us/step - loss: 1.2757 - acc: 0.6056\n",
            "Generating text from the seed : e queen was silent.  \n",
            "\n",
            "e queen was silent. the mock turtle said the mock turtle said the mock turtle said the mock turtle said the mock turtle ==================================================\n",
            "Iteration #: 7\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 920us/step - loss: 1.2236 - acc: 0.6185\n",
            "Generating text from the seed : aid, everybody has w \n",
            "\n",
            "aid, everybody has was the same the same thing the sea, and the mouse was the same the same thing the sea, and the mouse==================================================\n",
            "Iteration #: 8\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 920us/step - loss: 1.1806 - acc: 0.6319\n",
            "Generating text from the seed : est of the pack, she \n",
            "\n",
            "est of the pack, she had to herself to the court have to herself to the court have to herself to the court have to herse==================================================\n",
            "Iteration #: 9\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 920us/step - loss: 1.1349 - acc: 0.6427\n",
            "Generating text from the seed : e project gutenberg- \n",
            "\n",
            "e project gutenberg-tm electronic works and the work of the project gutenberg literary archive foundation the project gu==================================================\n",
            "Iteration #: 10\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 920us/step - loss: 1.0970 - acc: 0.6525\n",
            "Generating text from the seed : *    *    *    *     \n",
            "\n",
            "*    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    ==================================================\n",
            "Iteration #: 11\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 923us/step - loss: 1.0600 - acc: 0.6638\n",
            "Generating text from the seed : ld your tongue! said \n",
            "\n",
            "ld your tongue! said the mock turtle said: it was a large of the same of the same of the same of the same of the same of==================================================\n",
            "Iteration #: 12\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 147s 924us/step - loss: 1.0229 - acc: 0.6735\n",
            "Generating text from the seed : same thing, you know \n",
            "\n",
            "same thing, you know, said the mouse, and the mouse went on the sea, and the mouse went on the sea, and the mouse went o==================================================\n",
            "Iteration #: 13\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 922us/step - loss: 0.9885 - acc: 0.6830\n",
            "Generating text from the seed : rt of present! thoug \n",
            "\n",
            "rt of present! thought alice sounded the sole of the sort of the sort of the sort of the sort of the sort of the sort of==================================================\n",
            "Iteration #: 14\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 922us/step - loss: 0.9547 - acc: 0.6933\n",
            "Generating text from the seed :  will you, wont you, \n",
            "\n",
            " will you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you,==================================================\n",
            "Iteration #: 15\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 147s 923us/step - loss: 0.9160 - acc: 0.7055\n",
            "Generating text from the seed : irections, just like \n",
            "\n",
            "irections, just like the same thing that the sea, and the moment the sounce of the sea, and the moment the sounce of the==================================================\n",
            "Iteration #: 16\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 920us/step - loss: 0.8844 - acc: 0.7136\n",
            "Generating text from the seed : res first, said the  \n",
            "\n",
            "res first, said the dormouse, and the mock turtle sang the sense to the dormouse, and the mock turtle sang the sense to ==================================================\n",
            "Iteration #: 17\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 919us/step - loss: 0.8494 - acc: 0.7256\n",
            "Generating text from the seed :  got thrown out to s \n",
            "\n",
            " got thrown out to see it wonder the project gutenberg-tm electronically anything that it was a baby to change the subje==================================================\n",
            "Iteration #: 18\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 918us/step - loss: 0.8181 - acc: 0.7346\n",
            "Generating text from the seed : ing, but who has won \n",
            "\n",
            "ing, but who has won a little shriek, and she was a little shriek, and she was a little shriek, and she was a little shr==================================================\n",
            "Iteration #: 19\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 919us/step - loss: 0.7829 - acc: 0.7446\n",
            "Generating text from the seed : saying, in a solemn  \n",
            "\n",
            "saying, in a solemn tone, and all the time she walked off together. alice was genting out of the could be the same thing==================================================\n",
            "Iteration #: 20\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 922us/step - loss: 0.7533 - acc: 0.7545\n",
            "Generating text from the seed :  trembling voice, le \n",
            "\n",
            " trembling voice, let me see: is the same thing as i do. so she sat on the shrill about in a sort of chance of the soldi==================================================\n",
            "Iteration #: 21\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 147s 923us/step - loss: 0.7203 - acc: 0.7642\n",
            "Generating text from the seed : rs dream. the long g \n",
            "\n",
            "rs dream. the long grass and stocking over their heads of the sea, and she was a little shark of the sea, and she was a ==================================================\n",
            "Iteration #: 22\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 147s 923us/step - loss: 0.6927 - acc: 0.7727\n",
            "Generating text from the seed : even before she got  \n",
            "\n",
            "even before she got to see it would be offended, and the two creatures, and the mock turtle sang the sentence in the air==================================================\n",
            "Iteration #: 23\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 919us/step - loss: 0.6578 - acc: 0.7838\n",
            "Generating text from the seed : nting, and asking, b \n",
            "\n",
            "nting, and asking, but it cant see your majesty, said the mock turtle a little station as it spokes in the same thing as==================================================\n",
            "Iteration #: 24\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 146s 923us/step - loss: 0.6346 - acc: 0.7921\n",
            "Generating text from the seed : ll size by this time \n",
            "\n",
            "ll size by this time, she said to herself, as she swam all can again, and she tried the dormouse, and he wasnt one to se\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLzGs20p-b0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "fe79ac15-e48f-44be-90d5-d8a99c66bcb7"
      },
      "source": [
        "for iteration in range(5):\n",
        "    print('='*50)\n",
        "    print(\"Iteration #: %d\"%(iteration))\n",
        "    model.fit(x, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "    print(\"Generating text from the seed : %s \\n\"%(test_chars))\n",
        "    print(test_chars, end='')\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "        X_test = np.zeros((1, SEQ_LEN, len_chars))\n",
        "        for i, ch in enumerate(test_chars):\n",
        "            X_test[0, i, chars2index[ch]] = 1\n",
        "        pred = model.predict(X_test, verbose=False)[0]\n",
        "        y_pred = index2chars[np.argmax(pred)]\n",
        "        print(y_pred, end='')\n",
        "        test_chars=test_chars[1:] + y_pred\n",
        "print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 912us/step - loss: 0.6070 - acc: 0.7995\n",
            "Generating text from the seed :  a very interesting  \n",
            "\n",
            " a very interesting the table, and sometimes she could hear the matter where you are out of the work in a moment that sh==================================================\n",
            "Iteration #: 1\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 911us/step - loss: 0.5795 - acc: 0.8092\n",
            "Generating text from the seed : reat hall, with the  \n",
            "\n",
            "reat hall, with the bottle as she picked her so, said alice, a little snar offended togeing itself up and a poor and lit==================================================\n",
            "Iteration #: 2\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 912us/step - loss: 0.5520 - acc: 0.8175\n",
            "Generating text from the seed : t slowly after it: i \n",
            "\n",
            "t slowly after it: i shall dinah are oftended tone, and a large plate came to the project gutenberg literary archive fou==================================================\n",
            "Iteration #: 3\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 915us/step - loss: 0.5327 - acc: 0.8240\n",
            "Generating text from the seed : rmances and research \n",
            "\n",
            "rmances and research. at last the dodo said, that in another must at speak? i shall sit here, thought alice. i dont thin==================================================\n",
            "Iteration #: 4\n",
            "Epoch 1/1\n",
            "158763/158763 [==============================] - 145s 915us/step - loss: 0.5068 - acc: 0.8324\n",
            "Generating text from the seed : m both the project g \n",
            "\n",
            "m both the project gutenberg-tms goals by the bill, said the mock turtle. she was to him, the mock turtle said: but i sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ-CpZ5pCkyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoN8xA_gEv7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_9tj1YAILwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b8e80e9f-a83c-4244-e832-f80db5d3f0d7"
      },
      "source": [
        "model_1.evaluate(x,y,verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "158763/158763 [==============================] - 208s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4339650188220227, 0.8609688655432212]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBnl5yUfGBlr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "270188a6-010a-43f6-d851-59bc29082869"
      },
      "source": [
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "    print(\"Generating text from the seed : %s \\n\"%(test_chars))\n",
        "    print(test_chars, end='')\n",
        "    for i in range(1000):\n",
        "        X_test = np.zeros((1, SEQ_LEN, len_chars))\n",
        "        for i, ch in enumerate(test_chars):\n",
        "            X_test[0, i, chars2index[ch]] = 1\n",
        "        pred = model_1.predict(X_test, verbose=False)[0]\n",
        "        y_pred = index2chars[np.argmax(pred)]\n",
        "        print(y_pred, end='')\n",
        "        test_chars=test_chars[1:] + y_pred\n",
        "        if (y_pred == '.') or y_pred == ',' or y_pred==':':\n",
        "          print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating text from the seed :  foundation, the tra \n",
            "\n",
            " foundation, the trademark owner,\n",
            " said the king.\n",
            " when she was to herself,\n",
            " as she went on against it:\n",
            " at last the little bittle bit stop in the subjects of te libus,\n",
            " still it had to late the table,\n",
            " and the words came upon a tree in any walk in the fand of great descoftly swam of dear! but those cause the mock turtle sang this:\n",
            " lasted their heads off? to look through the was of the baby?,\n",
            " im too much far and all the panther is,\n",
            " said the king.\n",
            " when she was to herself,\n",
            " as she went on against it:\n",
            " at last the little bittle bit stop in the subjects of te libus,\n",
            " still it had to late the table,\n",
            " and the words came upon a tree in any walk in the fand of great descoftly swam of dear! but those cause the mock turtle sang this:\n",
            " lasted their heads off? to look through the was of the baby?,\n",
            " im too much far and all the panther is,\n",
            " said the king.\n",
            " when she was to herself,\n",
            " as she went on against it:\n",
            " at last the little bittle bit stop in the subjects of te libus,\n",
            " still it had to late the table,\n",
            " and the words came upon a tree "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvTsTwmeHIxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}